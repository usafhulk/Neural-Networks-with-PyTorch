{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50a4e1b6",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression (MLR) in PyTorch â€” Notebook Summary & Interpretation\n",
    "\n",
    "This notebook demonstrates how to perform multiple linear regression using PyTorch, both manually and with built-in modules. Below is a summary and interpretation of the key steps and results.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. **Manual Prediction with Custom Weights and Bias**\n",
    "\n",
    "- **Weights and Bias:**  \n",
    "  The notebook starts by manually setting weights (`w`) and bias (`b`) for a regression model with two input features.\n",
    "- **Prediction Function:**  \n",
    "  A custom `forward` function is defined to compute predictions using matrix multiplication (`torch.mm`) and bias addition.\n",
    "- **Single Sample Prediction:**  \n",
    "  For an input `x = [[1.0, 2.0]]`, the model computes the output using the manually set weights and bias.\n",
    "- **Batch Prediction:**  \n",
    "  The same function is used to predict outputs for a batch of samples, showing how the model generalizes to multiple inputs.\n",
    "\n",
    "**Interpretation:**  \n",
    "This section illustrates the mechanics of linear regression: predictions are made by multiplying inputs by weights and adding a bias. The results confirm the expected output for both single and multiple samples.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. **Using PyTorch's Built-in Linear Layer**\n",
    "\n",
    "- **Model Creation:**  \n",
    "  A `nn.Linear` model is instantiated for two input features and one output.\n",
    "- **Predictions:**  \n",
    "  The model is used to predict outputs for both a single sample and a batch of samples.\n",
    "- **Random Initialization:**  \n",
    "  The weights and bias are randomly initialized, so predictions will differ from the manual case unless trained.\n",
    "\n",
    "**Interpretation:**  \n",
    "PyTorch's `nn.Linear` automates the weight and bias handling, making it easy to scale up to more complex models. The predictions at this stage are random, as the model has not been trained.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. **Custom Linear Regression Class**\n",
    "\n",
    "- **Class Definition:**  \n",
    "  A custom `linear_regression` class is defined, inheriting from `nn.Module` and using an internal `nn.Linear` layer.\n",
    "- **Parameter Inspection:**  \n",
    "  The model's parameters (weights and bias) are printed both as a list and as a state dictionary.\n",
    "- **Predictions:**  \n",
    "  The custom model is used to predict outputs for both single and multiple samples.\n",
    "\n",
    "**Interpretation:**  \n",
    "Defining a custom class allows for more flexibility and extensibility, such as adding custom methods or additional layers. The predictions again reflect the random initialization of weights and bias.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. **Practice: Predicting with a Larger Input Tensor**\n",
    "\n",
    "- **Input Tensor:**  \n",
    "  The model is tested on a larger input tensor `X = [[11, 12, 13, 14], [11, 12, 13, 14]]` using a custom linear regression class with four input features.\n",
    "- **Prediction:**  \n",
    "  The model outputs predictions for each row in the input tensor.\n",
    "\n",
    "**Interpretation:**  \n",
    "This demonstrates that the custom linear regression model can handle any input size as long as it matches the expected number of features. The predictions are again based on randomly initialized weights and bias.\n",
    "\n",
    "---\n",
    "\n",
    "## **Overall Summary**\n",
    "\n",
    "- The notebook walks through manual and automated approaches to multiple linear regression in PyTorch.\n",
    "- It shows how to set up weights and bias, define prediction functions, and use both built-in and custom model classes.\n",
    "- Predictions before training are based on initial weights and bias, so they are not meaningful until the model is trained.\n",
    "- The workflow provides a foundation for understanding and implementing linear regression for more complex datasets and models in PyTorch.\n",
    "\n",
    "---\n",
    "**Tip:**  \n",
    "To obtain meaningful predictions, you would typically train the model using a loss function and an optimizer to adjust the weights and bias based on real data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6555c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x78e607686170>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff13c6d",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result:  tensor([[9.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Set the weight and bias\n",
    "\n",
    "w = torch.tensor([[2.0], [3.0]], requires_grad=True)  # Weight tensor for 2 input features, shape (2, 1)\n",
    "b = torch.tensor([[1.0]], requires_grad=True)         # Bias tensor, shape (1, 1), requires gradient\n",
    "\n",
    "# Define Prediction Function\n",
    "\n",
    "def forward(x):\n",
    "    yhat = torch.mm(x, w) + b  # Matrix multiply input x with weights w, then add bias b\n",
    "    return yhat  # Return the predicted output\n",
    "\n",
    "# Calculate yhat\n",
    "\n",
    "x = torch.tensor([[1.0, 2.0]])  # Input sample with 2 features\n",
    "yhat = forward(x)               # Compute prediction using the forward function\n",
    "print(\"The result: \", yhat)     # Print the predicted output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18b68cb",
   "metadata": {},
   "source": [
    "# Each Row in the Following Tensor will Represent a Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result:  tensor([[ 6.],\n",
      "        [ 9.],\n",
      "        [12.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Sample tensor X\n",
    "\n",
    "X = torch.tensor([[1.0, 1.0],   # First sample: feature1=1.0, feature2=1.0\n",
    "                  [1.0, 2.0],   # Second sample: feature1=1.0, feature2=2.0\n",
    "                  [1.0, 3.0]])  # Third sample: feature1=1.0, feature2=3.0\n",
    "\n",
    "# Make the prediction of X \n",
    "\n",
    "yhat = forward(X)  # Compute predictions for all samples in X using the forward function\n",
    "print(\"The result: \", yhat)  # Print the predicted outputs for each sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194c6dd9",
   "metadata": {},
   "source": [
    "# Class Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result:  tensor([[-0.3969]], grad_fn=<AddmmBackward0>)\n",
      "The result:  tensor([[-0.0848],\n",
      "        [-0.3969],\n",
      "        [-0.7090]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Make a linear regression model using built-in function\n",
    "\n",
    "model = nn.Linear(2, 1)  # Create a linear regression model with 2 input features and 1 output\n",
    "\n",
    "# Make a prediction of x\n",
    "\n",
    "yhat = model(x)  # Predict output for single sample x using the built-in model\n",
    "print(\"The result: \", yhat)\n",
    "\n",
    "# Make a prediction of X\n",
    "\n",
    "yhat = model(X)  # Predict outputs for all samples in X using the built-in model\n",
    "print(\"The result: \", yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb7c83a",
   "metadata": {},
   "source": [
    "# Building a Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create linear_regression Class\n",
    "\n",
    "class linear_regression(nn.Module):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(linear_regression, self).__init__()  # Call parent class constructor\n",
    "        self.linear = nn.Linear(input_size, output_size)  # Define linear layer\n",
    "    \n",
    "    # Prediction function\n",
    "    def forward(self, x):\n",
    "        yhat = self.linear(x)  # Forward pass through linear layer\n",
    "        return yhat\n",
    "\n",
    "model = linear_regression(2, 1)  # Instantiate the model with 2 input features and 1 output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The parameters:  [Parameter containing:\n",
      "tensor([[ 0.3319, -0.6657]], requires_grad=True), Parameter containing:\n",
      "tensor([0.4241], requires_grad=True)]\n",
      "The parameters:  OrderedDict([('linear.weight', tensor([[ 0.3319, -0.6657]])), ('linear.bias', tensor([0.4241]))])\n",
      "The result:  tensor([[-0.5754]], grad_fn=<AddmmBackward0>)\n",
      "The result:  tensor([[ 0.0903],\n",
      "        [-0.5754],\n",
      "        [-1.2411]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Print model parameters\n",
    "\n",
    "print(\"The parameters: \", list(model.parameters()))  # List of Parameter objects (weights and bias)\n",
    "\n",
    "# Print model parameters (state dict)\n",
    "\n",
    "print(\"The parameters: \", model.state_dict())  # Dictionary of parameter names and tensors\n",
    "\n",
    "# Make a prediction of x\n",
    "\n",
    "yhat = model(x)  # Predict output for single sample x using the custom model\n",
    "print(\"The result: \", yhat)\n",
    "\n",
    "# Make a prediction of X\n",
    "\n",
    "yhat = model(X)  # Predict outputs for all samples in X using the custom model\n",
    "print(\"The result: \", yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values:\n",
      " tensor([[2.1062],\n",
      "        [2.1062]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Building a model to predict the following tensor.\n",
    "# X = torch.tensor([[11.0, 12.0, 13, 14], [11, 12, 13, 14]])\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Define the input tensor X\n",
    "X = torch.tensor([[11.0, 12.0, 13.0, 14.0],\n",
    "                  [11.0, 12.0, 13.0, 14.0]])\n",
    "\n",
    "# Define the custom linear regression class\n",
    "class linear_regression(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(linear_regression, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "# Instantiate the model for 4 input features and 1 output\n",
    "model = linear_regression(4, 1)\n",
    "\n",
    "# Make predictions using the model\n",
    "yhat = model(X)\n",
    "print(\"Predicted values:\\n\", yhat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_gpu_clean)",
   "language": "python",
   "name": "tf_gpu_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
