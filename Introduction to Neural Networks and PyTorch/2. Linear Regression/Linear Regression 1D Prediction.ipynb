{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IeGtvZYf_BuJ"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prediction <br/>\n",
        "\n",
        "Creating the following expressions\n",
        "\n",
        "$b=-1,w=2$\n",
        "\n",
        "$\\hat{y}=-1+2x$"
      ],
      "metadata": {
        "id": "rZjjjh-O_OEX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define parameters w = 2 and b = -1 for y = wx + b\n",
        "\n",
        "w = torch.tensor(2.0, requires_grad = True)\n",
        "b = torch.tensor(-1.0, requires_grad = True)"
      ],
      "metadata": {
        "id": "_KaFKu2h_LFk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the function <code>forward(x, w, b)</code> makes the prediction:"
      ],
      "metadata": {
        "id": "EifH6aC5_ezM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function forward(x) for prediction\n",
        "\n",
        "def forward(x):\n",
        "    yhat = w * x + b\n",
        "    return yhat"
      ],
      "metadata": {
        "id": "ruggO4iA_cO8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making predictions for x=1\n",
        "\n",
        "$\\hat{y}=-1+2x$\n",
        "\n",
        "$\\hat{y}=-1+2(1)$"
      ],
      "metadata": {
        "id": "6U8SAmRg_kW-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict y = 2x - 1 at x = 1\n",
        "\n",
        "x = torch.tensor([[1.0]])\n",
        "yhat = forward(x)\n",
        "print(\"The prediction: \", yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7Nr7oBG_iH5",
        "outputId": "b25c6a7f-ce4e-4741-928a-89ff94977d81"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The prediction:  tensor([[1.]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prediction for multiple inputs"
      ],
      "metadata": {
        "id": "SGafoBK7_y75"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "construct the <code>x</code> tensor first then check the shape of <code>x</code>."
      ],
      "metadata": {
        "id": "K5zmL1dp__S3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create x Tensor and check the shape of x tensor\n",
        "\n",
        "x = torch.tensor([[1.0], [2.0]])\n",
        "print(\"The shape of x: \", x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8WpaObS__Ew",
        "outputId": "ba17629e-6101-4214-bc84-b87579d006f1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of x:  torch.Size([2, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make the prediction of y = 2x - 1 at x = [1, 2]\n",
        "\n",
        "yhat = forward(x)\n",
        "print(\"The prediction: \", yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cWCC6_O_tcO",
        "outputId": "9bb28c27-d572-4461-aaf0-cc1ced4e960e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The prediction:  tensor([[1.],\n",
            "        [3.]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making a prediction of the following <code>x</code> tensor using the <code>w</code> and <code>b</code> from above.\n"
      ],
      "metadata": {
        "id": "U38FeVp3Ac2y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a prediction of y = 2x - 1 at x = [[1.0], [2.0], [3.0]]\n",
        "\n",
        "x = torch.tensor([[1.0], [2.0], [3.0]])\n",
        "print(\"The shape of x: , x.shape\")\n",
        "\n",
        "# Make the prediction\n",
        "yhat = forward(x)\n",
        "print(\"The prediction: \", yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BoDXtePAGPv",
        "outputId": "8122903b-909b-4e7d-8c93-428c8701408f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of x: , x.shape\n",
            "The prediction:  tensor([[1.],\n",
            "        [3.],\n",
            "        [5.]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3 id=\"Linear\">Class Linear</h3>"
      ],
      "metadata": {
        "id": "-Qmcs9SKBTqt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. The linear class can be used to make a prediction and the linear class to build more complex models.\n",
        "2. Set the random seed because the parameters are randomly initialized\n",
        "3.  linear object using the constructor and the parameters are already randomly created. I am printing out to see what <i>w</i> and <i>b</i>.\n",
        "4. The parameters of an <code>torch.nn.Module</code> model are contained in the modelâ€™s parameters accessed with <code>lr.parameters()</code>\n",
        "5. equivalent to this below:\n",
        "\n",
        "$b=-0.44, w=0.5153$<br/>\n",
        "$\\hat{y}=-0.44+0.5153x$"
      ],
      "metadata": {
        "id": "j0hPFA5pBdgE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import Linear\n",
        "\n",
        "torch.manual_seed(1)\n",
        "lr = Linear(in_features=1, out_features=1, bias=True)\n",
        "print(\"Parameters w and b: \", list(lr.parameters()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzyxPsGwBDeF",
        "outputId": "c1b2e2a7-2da5-48b1-948c-33259d82145e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters w and b:  [Parameter containing:\n",
            "tensor([[0.5153]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.4414], requires_grad=True)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " <code>state_dict()</code> Returns a Python dictionary object corresponding to the layers of each parameter  tensor."
      ],
      "metadata": {
        "id": "ZP4_5T2xCRfS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Python dictionary: \",lr.state_dict())\n",
        "print(\"keys: \",lr.state_dict().keys())\n",
        "print(\"values: \",lr.state_dict().values())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ip9jmwFrBoME",
        "outputId": "e3aeadb0-fdb9-4c05-c2ca-3372f65786b9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python dictionary:  OrderedDict([('weight', tensor([[0.5153]])), ('bias', tensor([-0.4414]))])\n",
            "keys:  odict_keys(['weight', 'bias'])\n",
            "values:  odict_values([tensor([[0.5153]]), tensor([-0.4414])])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"weight:\",lr.weight)\n",
        "print(\"bias:\",lr.bias)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGpVGulJCabr",
        "outputId": "c0670ff0-6878-4848-8149-b682ee92e759"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weight: Parameter containing:\n",
            "tensor([[0.5153]], requires_grad=True)\n",
            "bias: Parameter containing:\n",
            "tensor([-0.4414], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making a single prediction at <i>x = [[1.0]]</i>."
      ],
      "metadata": {
        "id": "xd-CEgAdCXF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make the prediction at x = [[1.0]]\n",
        "\n",
        "x = torch.tensor([[1.0]])\n",
        "yhat = lr(x)\n",
        "print(\"The prediction: \", yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikzLbxEWCT-d",
        "outputId": "84899e87-031c-4b06-d51a-607af33a1a99"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The prediction:  tensor([[0.0739]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I can also use the model <code>lr(x)</code> to predict multiple results"
      ],
      "metadata": {
        "id": "yDvcFAjbCoqe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the prediction using linear model\n",
        "\n",
        "x = torch.tensor([[1.0], [2.0]])\n",
        "yhat = lr(x)\n",
        "print(\"The prediction: \", yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1FdwdFJCjaX",
        "outputId": "a76d415c-1579-47cd-fe98-4739d9290d2b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The prediction:  tensor([[0.0739],\n",
            "        [0.5891]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making a prediction of the following <code>x</code> tensor using the linear regression model <code>lr</code>."
      ],
      "metadata": {
        "id": "bRtk1mswC1DR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the linear regression model object lr to make the prediction.\n",
        "\n",
        "x = torch.tensor([[1.0],[2.0],[3.0]])\n",
        "yhat = lr(x)\n",
        "print(\"The prediction: \", yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lf534WKTCoBC",
        "outputId": "11c03ed4-6dd7-4706-99d9-19f4f1f72ecd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The prediction:  tensor([[0.0739],\n",
            "        [0.5891],\n",
            "        [1.1044]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building a Custom Model"
      ],
      "metadata": {
        "id": "OaabRoGuDD86"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "class LR_model(nn.Module):\n",
        "  # constructor\n",
        "  def __init__(self, input_size, output_size):\n",
        "    # inheriting from the parent\n",
        "    super(LR_model, self).__init__()\n",
        "    self.linear = nn.Linear(input_size, output_size)\n",
        "\n",
        "  # prediction function\n",
        "  def forward(self, x):\n",
        "    yhat = self.linear(x)\n",
        "    return yhat"
      ],
      "metadata": {
        "id": "pn7zcvJCDAkB"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating the object using the constructor and printing the paramenters + model."
      ],
      "metadata": {
        "id": "l0Pds4WIDvKb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LR_model(1,1)\n",
        "print(\"The parameters: \", list(lr.parameters()))\n",
        "print(\"Linear model: \", lr.linear)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72dTnsgqDuR5",
        "outputId": "3c985422-fda8-4f72-e728-6d662a2c4d76"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The parameters:  [Parameter containing:\n",
            "tensor([[-0.1939]], requires_grad=True), Parameter containing:\n",
            "tensor([0.4694], requires_grad=True)]\n",
            "Linear model:  Linear(in_features=1, out_features=1, bias=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Try our customize linear regression model with single input\n",
        "\n",
        "x = torch.tensor([[1.0]])\n",
        "yhat = lr(x)\n",
        "print(\"The prediction: \", yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxEWMscwEOP0",
        "outputId": "353520f4-a1f5-499d-a1a2-126a5e1c3e04"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The prediction:  tensor([[0.2755]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Storing the parameters in a dictionary."
      ],
      "metadata": {
        "id": "S2LvHNMzEWKO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Python dictionary: \", lr.state_dict())\n",
        "print(\"keys: \",lr.state_dict().keys())\n",
        "print(\"values: \",lr.state_dict().values())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAuVMVCFESpZ",
        "outputId": "eff32c91-8b60-443a-98d7-5087fbe57b29"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python dictionary:  OrderedDict([('linear.weight', tensor([[-0.1939]])), ('linear.bias', tensor([0.4694]))])\n",
            "keys:  odict_keys(['linear.weight', 'linear.bias'])\n",
            "values:  odict_values([tensor([[-0.1939]]), tensor([0.4694])])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating an object <code>lr1</code> from the class created before and making a prediction."
      ],
      "metadata": {
        "id": "GCzOJbSYErE_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the LR class to create a model and make a prediction of the following tensor.\n",
        "\n",
        "x = torch.tensor([[1.0], [2.0], [3.0]])\n",
        "\n",
        "lr1 = LR_model(1,1)\n",
        "yhat = lr1(x)\n",
        "print(\"The prediction: \", yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uI2HSQ-5EViD",
        "outputId": "f019659f-b52d-41a7-dc60-0e307d061d32"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The prediction:  tensor([[-0.3417],\n",
            "        [-1.2832],\n",
            "        [-2.2246]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    }
  ]
}